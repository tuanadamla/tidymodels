{"metadata":{"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"},"kernelspec":{"name":"ir","display_name":"R","language":"R"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Exploration & Research\n\nTuana Damla Ünal","metadata":{}},{"cell_type":"code","source":"library(tidymodels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Introduction: \n## Summary Information\n\n\"tidymodels\" is a meta-package that provides functions, demonstrations and interfaces for statistical analysis and modeling. \n\n## Sub-Packages\nIt includes the below core sub-packages:\n\n- broom: This package provides 3 main functions (tidy(), glance() & augment()) to simplify the model results, summarize make them more workable for further implications. \n- dials: Dials package is a fune-tuning package for models. As indicated in some websites, it works really well with parsnip package models. \n- dplyr: It has efficient and useful functions for data manipulation and wrangling purposes. Most common functions can be listed as select(), mutate(), filter(), etc. \n- ggplot2: ggplot2 is a package for creating more good-looking, detailed and specific visualizations including histograms, plots, pie charts, line charts.  \n- infer: Infer is a package for statistical inference. Its main functions are specify(), hypothesize(), generate() and calculate(). \n- modeldata: Modeldata is a package that consists of many datatsets to be used for modeling purposes.\n- parsnip: This package provides a tidy and unified interface for many data modeling without a need of many packages. \n- purr: Purr helps and improves functional programming with many tools to ease working with vectors and functions. \n- recipes: Recipes is a method for creating regressor matrix for modeling and visualizations.\n- rsample: It has some tools and functions that enables resampling for testing the model.\n- tibble: Tibble is a reimaging of a data frame. It keeps the necessary informations only, but have some problems compared to data frames like it is impossible to change a variable in a tibble. \n- tidyr: Main objective of the tidyr is tidying the data. It does pivotting, rectangling, nesting, splitting and completing missing values. \n- tune: The goal of tune is providing hyperparameter tuning for tidymodels packages like recipes, parsnip and dials. \n- workflows: Workflows ease creating models that have multiple steps. \n- yardstick: The packages consists of functions for evaluating the model. (RMSE, accuracy, etc.)","metadata":{}},{"cell_type":"markdown","source":"# Advantages and Disadvantages of Tidymodels\n\n## Comparison with Other Model\n\n### Tidymodels vs. Mlr3\n\n+ Tidymodels have more functionality for the preprocessing step. However, the nested resampling procedure is more straightforward and clean in mlr3.\n+ Both packages have functions that can provide to work with workflows and piplines, however, mlr3 does not have some functions that can enable to work for individual steps in this flows. (step_unknown, step_other, step_novel) \n+ Mlr3 have a framework named GraphLearner which takes graphs and strings together the preprocessing, hyperparameter tuning, and prediction process as a Graph Network.\n\n\n### Tidymodels & Mlflow\n\n+ A few people suggest that a comparison is not logical for mlflow and tidymodels, they complete each other.\n+ Mlflow can help collecting model parameters, metrics and artefacts, and displays them in a pretty UI with its tracking feature. The tidymodels packages integrate very nicely with MLflow, and allow for automating some parts of the tracking.\n+ Tidymodels presents an excellent opportunity to make life a bit easier for R users who want to take advantage of MLflow. \n\n### Tidymodels vs. Caret\n\n+ Tidymodels is providing tiny and neat outcomes that can offer a great deal of granularity to the end user. \n+ Tidymodels includes very useful packages that can enable analysing the model estimated probabilities and resampled performances. \n+ The great advantage of caret is that it combines many small code pieces in just one. It also makes sure it’s done as fast as possible.\n+ Tidymodels takes over 1 minute while caret only needs 4–5 seconds to run decision tree.\n\n## Pros and Cons in General\n\n### Pros\n\n+ Packages are flexible and modular.\n+ It provides tidy outcomes.\n+ In the tidymodels ecosystem, workflows package is used to bundle together model components and promote more fluent modeling processes.\n+ There are many benefits from making it easier to keep track of model components to avoiding data leakage in feature engineering.\n\n### Cons\n\n+ It is a newer framework of a robust successor \"caret\". \n+ It can be challenging for a newcomer to know where their specific problem fits in this ecosystem due to the modularity.\n+ Its speed performance can be worse than other packages. \n+ There are still room for improvement with new functionalities. ","metadata":{}},{"cell_type":"markdown","source":"# Resources\n\n+ https://tidymodels.tidymodels.org\n+ https://cran.r-project.org/web/packages/tidymodels/tidymodels.pdf\n+ https://mdneuzerling.com/post/tracking-tidymodels-with-mlflow/\n+ https://pharmacoecon.me/post/2021-05-01-tidymodels-vs-mlr3/\n+ https://konradsemsch.netlify.app/2019/08/caret-vs-tidymodels-comparing-the-old-and-new/\n+ https://towardsdatascience.com/caret-vs-tidymodels-how-to-use-both-packages-together-ee3f85b381c\n+ https://www.tidyverse.org/blog/2021/05/choose-tidymodels-adventure/\n+ https://www.tidymodels.org/start/tuning/","metadata":{}},{"cell_type":"markdown","source":"# Examples from AD454 Lab Cases\n\n## - Broom Package\n\nWe generally use summary() function for reading the model. However, broom's tidy(), glance() and augment() functions have better implications.","metadata":{}},{"cell_type":"code","source":"datapath <- \"~/data_ad454\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"realty_data <- readRDS(sprintf(\"%s/rds/02_01_realty_data.rds\", datapath))\nfeatures <- c(\"price\", \"brut_metrekare\",\n             \"krediye_uygunluk\",\n             \"kira_getirisi\")\nrealty_data2 <- realty_data %>%\nselect(all_of(features)) %>%\nmutate(unit_price = price / brut_metrekare) %>%\nmutate(unit_rent = kira_getirisi / brut_metrekare) %>%\nfilter(krediye_uygunluk == \"uygun\") %>%\nna.omit %>%\nfilter(between(unit_price, quantile(unit_price, 0.05), quantile(unit_price, 0.95))) %>%\nfilter(between(unit_rent, quantile(unit_rent, 0.05), quantile(unit_rent, 0.95)))\n\nmodel1 <- lm(unit_price ~ unit_rent, data = realty_data2)\ntidy(model1) #gives the summary as a tibble to enable work for further anaylsis\nglance(model1) #summarizes model performance\naugment(model1) #summarizes all points in the model with their their errors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Yardstick Package\n\nIn the lab sessions, we are doing this evaluation table by defining a function. But yardstick has it by default.","metadata":{}},{"cell_type":"code","source":"table <- augment(model1)\nmetrics(table, truth = \"unit_price\", estimate = \".fitted\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tune & Dials Package\n\nWe have done loops for the optimal complexity, however tune package can does it automatically.","metadata":{}},{"cell_type":"code","source":"library(modeldata)\ndata(mlc_churn, package = \"modeldata\")\nchurn <- mlc_churn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We splitted the data to train to test sets with inital_split function.","metadata":{}},{"cell_type":"code","source":"set.seed(123)\ncell_split <- initial_split(churn, prop = 7/10)\ncell_train <- training(cell_split)\ncell_test  <- testing(cell_split)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We created the rpart model with decision tree and tune functions. ","metadata":{}},{"cell_type":"code","source":"tune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have selected levels and tuning parameter for our tree grid.","metadata":{}},{"cell_type":"code","source":"tree_grid <- grid_regular(cost_complexity(),\n                          levels = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We created the workflow to try different complexity parameters.","metadata":{}},{"cell_type":"code","source":"tree_wf <- workflow() %>%\n  add_model(tune_spec) %>%\n  add_formula(churn ~ .)\n\nset.seed(234)\ncell_folds <- vfold_cv(cell_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the 5 parameters, the model calculated from the beginning with resamples easily. Then we posted the summary metrics. Since data is big, the calculation takes time. Like I said earlier, some operations are slower with tidymodels. ","metadata":{}},{"cell_type":"code","source":"tree_res <- \n  tree_wf %>% \n  tune_grid(\n    resamples = cell_folds,\n    grid = tree_grid\n    )\ntree_res %>% \n  collect_metrics()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to see the above table demonstrated, I have created below graphs. By looking at them, we can say that the Model 4 has the highest accuracy and roc_auc terms. So, we should select it. ","metadata":{}},{"cell_type":"code","source":"tree_res %>%\n  collect_metrics() %>%\n  ggplot(aes(cost_complexity, mean)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we created the final workflow and had the final tree. ","metadata":{}},{"cell_type":"code","source":"best_tree <- tree_res %>%\n  select_best(\"roc_auc\")\n\nfinal_wf <- \n  tree_wf %>% \n  finalize_workflow(best_tree)\n\nfinal_tree <- \n  final_wf %>%\n  fit(data = cell_train) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}